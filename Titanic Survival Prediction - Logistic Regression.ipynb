{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d7b051e",
   "metadata": {},
   "source": [
    "## Titanic Survival Prediction Using the Logistic Regression Model\n",
    "This notebook shows the steps taken in training a Logistic Regression Model for making predictions of survival for passengers in the titanic shipwreck of 1912. The resulting prediction is for the purpose of submission to the Titanic competition on Kaggle.\n",
    "\n",
    "The notebook shows:\n",
    "\n",
    "-how to do some EDA to pre-processing the data for the model.\n",
    "-how to train a Logistic Regression Model using a training dataset.\n",
    "-how to test the trained model on test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14ac4d3",
   "metadata": {},
   "source": [
    "## Step 1 : Import the Dependencies for the Model\n",
    "It is worthy to note that the train-test-split is not imported from skicit-learn because the data has been split prior to the start of the task. If the data comes without a train-test split,  import train_test_split from the sklearn.model_selection to perform the split. Pandas and Numpy are imported for Data Manipulation and Wrangling while the Logistic Regression is imoorted from Skicit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2805872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e86900",
   "metadata": {},
   "source": [
    "## Step 2: Load Data, Perform Exploratory Analysis and Pre-Processing on Data\n",
    "- Identify Datatypes present and make appropriate conversions , if necessary.\n",
    "- Drop features that have excessive missing values and for those with few missing values, impute values for NaNs. \n",
    "- Create Dummies for categorical variables in the dataset (drop original dummy columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c9d2e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a263b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#For Train Data\n",
    "df_train.dtypes\n",
    "df_train.info()\n",
    "\n",
    "#For Test Data\n",
    "df_test.dtypes\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f6363b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Train\n",
    "cla = {1:\"First Class\", 2: \"Second Class\", 3 :\"Third Class\"}\n",
    "emb = {\"Q\" : \"Queenstown\" , \"S\" : \"Southampton\" , \"C\" : \"Cherbourg\" }\n",
    "df_train['Pclass'] = df_train['Pclass'].map(cla)\n",
    "df_train['Embarked'] = df_train['Embarked'].map(emb)\n",
    "\n",
    "#For Test\n",
    "cla = {1:\"First Class\", 2: \"Second Class\", 3 :\"Third Class\"}\n",
    "emb = {\"Q\" : \"Queenstown\" , \"S\" : \"Southampton\" , \"C\" : \"Cherbourg\" }\n",
    "df_test['Pclass'] = df_test['Pclass'].map(cla)\n",
    "df_test['Embarked'] = df_test['Embarked'].map(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf61da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"Name\", \"Cabin\",\"Ticket\"]\n",
    "dummy_cols = [\"Sex\", \"Pclass\",\"Embarked\"]\n",
    "\n",
    "#For Train\n",
    "dummies_tr = []\n",
    "for col in dummy_cols:\n",
    "    dummies_tr.append(pd.get_dummies(df_train[col]))\n",
    "\n",
    "df_dummy_tr = pd.concat(dummies_tr, axis = 1)\n",
    "df_train = pd.concat((df_train, df_dummy_tr), axis =1)\n",
    "\n",
    "df_train.drop(drop_cols, axis = 1, inplace = True)\n",
    "df_train.drop(dummy_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dc0252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"Name\", \"Cabin\",\"Ticket\"]\n",
    "dummy_cols = [\"Sex\", \"Pclass\",\"Embarked\"]\n",
    "\n",
    "#For Test\n",
    "dummies_te = []\n",
    "for col in dummy_cols:\n",
    "    dummies_te.append(pd.get_dummies(df_test[col]))\n",
    "\n",
    "df_dummy_te = pd.concat(dummies_te, axis = 1)\n",
    "df_test = pd.concat((df_test, df_dummy_te), axis =1)\n",
    "\n",
    "df_test.drop(drop_cols, axis = 1, inplace = True)\n",
    "df_test.drop(dummy_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "629f8c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Train\n",
    "df_train[\"Age\"] = df_train[\"Age\"].interpolate()\n",
    "df_train[\"Age\"] = df_train[\"Age\"].astype('int64')\n",
    "\n",
    "#For Test\n",
    "df_test[\"Fare\"] = df_test[\"Fare\"].interpolate()\n",
    "df_test[\"Age\"] = df_test[\"Age\"].interpolate()\n",
    "df_test[\"Age\"] = df_test[\"Age\"].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caffbf3",
   "metadata": {},
   "source": [
    "## Split the Data into Features and Target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ec07deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Data Feature and Target\n",
    "X = df_train[['Age','SibSp','Parch','Fare','female','male', 'First Class', 'Second Class', 'Third Class', 'Cherbourg',\n",
    "       'Queenstown', 'Southampton']]\n",
    "y = df_train[\"Survived\"]\n",
    "\n",
    "# Test Data Features\n",
    "X_test = df_test[['Age','SibSp','Parch','Fare','female','male', 'First Class', 'Second Class', 'Third Class', 'Cherbourg',\n",
    "       'Queenstown', 'Southampton']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7663d2f3",
   "metadata": {},
   "source": [
    "## Instantiate Model and Fit on the Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77b5bbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train Model on Train Dataset\n",
    "model = LogisticRegression(solver = \"liblinear\", max_iter = 1000, random_state = 42)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac25b3f8",
   "metadata": {},
   "source": [
    "## Predict Survival of Test Passengers Using Model Predictions of Test Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ae60782",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43d3c416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8002244668911336\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y, model.predict(X))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3736bc",
   "metadata": {},
   "source": [
    "## Print the Results and Export to CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39503683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "output = pd.DataFrame({'PassengerId': df_test.PassengerId, 'Survived': predict})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adf2d05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    265\n",
       "1    153\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70879963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

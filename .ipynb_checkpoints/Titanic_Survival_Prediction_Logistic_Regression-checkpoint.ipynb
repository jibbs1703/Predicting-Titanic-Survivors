{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab3c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dependencies for Running the Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129f9514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Datasets\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Check Data Information for Train Data\n",
    "df_train.dtypes\n",
    "df_train.info()\n",
    "\n",
    "# Check Data Information for Test Data\n",
    "df_test.dtypes\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b39c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carry out Preprocessing on Train Data and  Drop Unneeded Columns\n",
    "cla = {1:\"First Class\", 2: \"Second Class\", 3 :\"Third Class\"}\n",
    "emb = {\"Q\" : \"Queenstown\" , \"S\" : \"Southampton\" , \"C\" : \"Cherbourg\" }\n",
    "df_train['Pclass'] = df_train['Pclass'].map(cla)\n",
    "df_train['Embarked'] = df_train['Embarked'].map(emb)\n",
    "\n",
    "drop_cols = [\"Name\", \"Cabin\",\"Ticket\"]\n",
    "dummy_cols = [\"Sex\", \"Pclass\",\"Embarked\"]\n",
    "\n",
    "dummies_tr = []\n",
    "for col in dummy_cols:\n",
    "    dummies_tr.append(pd.get_dummies(df_train[col]))\n",
    "\n",
    "df_dummy_tr = pd.concat(dummies_tr, axis = 1)\n",
    "df_train = pd.concat((df_train, df_dummy_tr), axis =1)\n",
    "\n",
    "df_train.drop(drop_cols, axis = 1, inplace = True)\n",
    "df_train.drop(dummy_cols, axis=1, inplace=True)\n",
    "\n",
    "df_train[\"Age\"] = df_train[\"Age\"].interpolate()\n",
    "df_train[\"Age\"] = df_train[\"Age\"].astype('int64')\n",
    "\n",
    "# Carry out Preprocessing on Test Data and Drop Unneeded Columns\n",
    "cla = {1:\"First Class\", 2: \"Second Class\", 3 :\"Third Class\"}\n",
    "emb = {\"Q\" : \"Queenstown\" , \"S\" : \"Southampton\" , \"C\" : \"Cherbourg\" }\n",
    "df_test['Pclass'] = df_test['Pclass'].map(cla)\n",
    "df_test['Embarked'] = df_test['Embarked'].map(emb)\n",
    "\n",
    "drop_cols = [\"Name\", \"Cabin\",\"Ticket\"]\n",
    "dummy_cols = [\"Sex\", \"Pclass\",\"Embarked\"]\n",
    "\n",
    "dummies_te = []\n",
    "for col in dummy_cols:\n",
    "    dummies_te.append(pd.get_dummies(df_test[col]))\n",
    "\n",
    "df_dummy_te = pd.concat(dummies_te, axis = 1)\n",
    "df_test = pd.concat((df_test, df_dummy_te), axis =1)\n",
    "\n",
    "df_test.drop(drop_cols, axis = 1, inplace = True)\n",
    "df_test.drop(dummy_cols, axis=1, inplace=True)\n",
    "\n",
    "df_test[\"Fare\"] = df_test[\"Fare\"].interpolate()\n",
    "df_test[\"Age\"] = df_test[\"Age\"].interpolate()\n",
    "df_test[\"Age\"] = df_test[\"Age\"].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a591959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Data into Features and Target Variables\n",
    "# Train Data Feature and Target\n",
    "X = df_train[['Age','SibSp','Parch','Fare','female','male', 'First Class', 'Second Class', 'Third Class', 'Cherbourg',\n",
    "       'Queenstown', 'Southampton']]\n",
    "y = df_train[\"Survived\"]\n",
    "\n",
    "# Test Data Features\n",
    "X_test = df_test[['Age','SibSp','Parch','Fare','female','male', 'First Class', 'Second Class', 'Third Class', 'Cherbourg',\n",
    "       'Queenstown', 'Southampton']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d93f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate Logistic Regression Model and Fit the Model on the Training Dataset\n",
    "model = LogisticRegression(solver = \"liblinear\", max_iter = 1000, random_state = 42)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1879507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Accuracy of the Model with the Training Data\n",
    "train_acc = accuracy_score(y, model.predict(X))\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440bb8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Survival in the Test Dataset Using \"model.predict\" on the Test Features\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38717c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Results and Export to CSV File\n",
    "model_output = pd.DataFrame({'PassengerId': df_test.PassengerId, 'Survived': predictions})\n",
    "model_output.to_csv('titanic_survivors.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ced74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many survivors/non-survivors the Model Predicted\n",
    "model_output[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751fe6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the Model to a .py File Using the Pickle Module\n",
    "pickle.dump(model, open('model.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
